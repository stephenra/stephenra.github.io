{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"On conditioning by adaptive sampling (Part I) As my very first blog post, I thought I would look at a great, recent paper by David Brookes, Hahnbeom Park, and Jennifer Listgarten 1 , which extends their work from last year that posits a framework, Conditioning by Adaptive Sampling (CbAS) , for model-based conditional density estimation. Of particular relevance to drug design is the application to protein properties. For example, how do we go about optimizing the design of DNA sequences for protein expression, binding, or for protein sequences that maximize properties like secondary structure or fluorescence? Traditionally, in vitro methods for protein engineering have been exhaustive usually involving \"greedy walks\" through protein design space like directed evolution (DE) . This paper proposes a more efficient in silico approach. For this particular entry, I'll summarize the key contributions and introduce some of the core concepts. The subsequent post will walk through the Cross-Entropy Method (CEM) and their experimental results. Summary The main contributions of this paper are as follows: The authors present a method for tackling design problems in discrete space including the problem of maximizing protein fluorescence using avGFP sequence data from Sarkisyan et al. 2016 . A principled approach for conditional density estimation in the presence of rare events and which doesn't constrain the oracle by requiring differentiability. This has the added benefit of recapitulating models in various scientific domains which may not be readily differentiable to begin with It also allows for a degree of flexibility of validation by using wet-lab experiments as the oracle. An exact and iterative importance sampling-based estimation method for variance reduction and computationally intractable model densities. Generalizability of CbAS to specification of property values rather than solely maximization (e.g. a protein fluorescing at a desired wavelength as opposed to being maximally fluorescent). Oracles and oracle properties In order to understand the problem setting in the paper, it's worth briefly reviewing oracles. In statistics, oracle and oracle properties have been extensively used in the context of high-dimensional model estimation and feature selection whereby we have a response vector \\boldsymbol{y} = (y_1,...,y_n)^{T} and input vector of linearly independent features \\boldsymbol{x_j} = (x_{1j},...,x_{nj})^{T} with j = 1,..,p . Under the assumption that we have \\mathbb{A} = \\{ j: \\hat{\\beta} \\neq 0 \\} , the true model only depends on a subset X_{S} \\subset X of its feature space. Briefly put, an oracle property is a theoretical attribute ascribed to a model if it performs as well as if the correct underlying model were given in advance. More formally and following Fan and Li 2001 , Fan and Peng 2004 , and Zou 2006 , we call a given fitting procedure \\delta an oracle if \\hat{\\beta}(\\delta) , the coefficient estimator, identifies the right subset model, \\{ j: \\hat{\\beta} \\neq 0 \\} = \\mathbb{A} with some optimal estimation rate: \\sqrt{n} \\hat{\\beta}(\\delta)_{\\mathbb{A}} - \\beta^*_{\\mathbb{A}}) \\to \\mathcal{N} (0, I^{-1}(\\beta^*_\\mathbb{A})) Thus, the oracle property holds that the asymptotic distribution of the estimator is the same as the asymptotic distribution of the MLE only on the true support. That is, the estimator adapts to knowing the true support without incurring a price. Why is this important? For the authors, they argue that their oracle p(y|\\boldsymbol{x}) effectively serves as a proxy for expensive and exhaustive laboratory-based property measurements. They also make the assumption that given an input, such as a DNA sequence, the oracle 2 returns a distribution over the properties of interest. It's worth noting that this is within the context of the generative setting where we model the joint probability distribution p(\\boldsymbol{x}, y) . Given the property oracle then, one can subsequently model and empirically sample from the underlying data distribution p_{d}(\\boldsymbol{x}) with a generative model p(\\boldsymbol{x}|\\theta) whose prior is conditioned on the desiderata encoded in property values S . The claim here is that this gives a certain degree of flexibility in specifying priors on the design space, unlike G\u00f3mez-Bombarelli et al. 2018 and Killoran et al. 2017 , which utilize a fixed VAE and GAN respectively. Lastly, it's worth noting that they do not require their oracle to be differentiable and this additionally circumvents backpropagation through discrete input space. Conditioning by adaptive sampling The problem setting is as follows: find settings of the discrete random vector \\boldsymbol{x} \\in \\mathbb{N}^{L} (e.g. representative of DNA sequences) that have a high probability of satisfying some property desiderata (e.g. maximal fluoresence of a protein). The inference problem is expressed as: p(\\boldsymbol{x}|S, \\theta^{(0)}) = \\frac{P(S|\\boldsymbol{x})p(\\boldsymbol{x}|\\theta^{(0)})}{P(S|\\theta^{(0)})} p(\\boldsymbol{x}|S, \\theta^{(0)}) = \\frac{P(S|\\boldsymbol{x})p(\\boldsymbol{x}|\\theta^{(0)})}{P(S|\\theta^{(0)})} where P(S|\\theta^{(0)}) = \\int_{s} P(S|\\boldsymbol{x})p(\\boldsymbol{x}|\\theta^{(0)}) d\\boldsymbol{x} . Like variational inference , the marginal probability of CbAS yields no analytic solution as the sum over all possible configurations of the latent structures and its parameters is intractable. Unsurprisingly, inference for CbAS is VI-like in that they minimize the KL divergence between the conditional and the approximating search model, q(\\boldsymbol{x}|\\phi) : \\phi^{*} = \\underset{\\phi}{\\operatorname{argmin}} D_{KL} \\big(p(\\boldsymbol{x}|S,\\theta^{(0)})||q(\\boldsymbol{x}|\\phi\\big) \\phi^{*} = \\underset{\\phi}{\\operatorname{argmin}} D_{KL} \\big(p(\\boldsymbol{x}|S,\\theta^{(0)})||q(\\boldsymbol{x}|\\phi\\big) This can be re-written in terms of the log expectation of the difference between the search model distribution and the target conditional distribution, similar to how the Evidence Lower Bound (ELBO) can be derived: \\underset{\\phi}{\\operatorname{argmin}}\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log p(\\boldsymbol{x}|S,\\theta^{(0)}) - \\log q(\\boldsymbol{x}|\\phi)] \\underset{\\phi}{\\operatorname{argmin}}\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log p(\\boldsymbol{x}|S,\\theta^{(0)}) - \\log q(\\boldsymbol{x}|\\phi)] Thus, the second expectation can be expressed as the entropy of the target conditional distribution H_{0} \\equiv -\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log p(\\boldsymbol{x}|S,\\theta^{(0)})] : \\begin{align} & = \\underset{\\phi}{\\operatorname{argmin}}-\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log q(\\boldsymbol{x}|\\phi)] - H_{0} \\newline & = \\underset{\\phi}{\\operatorname{argmax}} \\frac{1}{P(S|\\theta^{(0)})} \\mathbb{E}_{(p(\\boldsymbol{x}|S,\\theta^{(0)})}[P(S|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)] \\newline & = \\underset{\\phi}{\\operatorname{argmax}}\\mathbb{E}_{p(\\boldsymbol{x}|\\theta^{(0)})}[P(S|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)] & \\scriptstyle{H_{0}, P(S|\\theta^{(0)}) \\text{ dropped}} \\\\[2mm] \\end{align} The authors also note that the difficulty of estimating the normalizing constant is compounded by the fact that S (and by definition, P(S|\\boldsymbol{x}) ) is \"exceedingly rare\". This translates to difficulties in optimization: any gradient-based reparameterization which yields differentiable Monte Carlo (MC) estimates of our expectation (i.e. the 'reparameterization trick' from Kingma and Welling 2014 ) would require a non-trivial number of samples to be accurate and be very challenging for distributions over discrete state spaces. To put it another way, any naive MC estimation would require an intensive simulation effort, inversely proportional to the magnitude of P(S|\\boldsymbol{x}) . Importance sampling-based estimation I'm not going to review importance sampling here 3 . Suffice to say that the basic idea is that we can estimate the expectation of a random variable under one distribution p(\\boldsymbol{x}) from samples of an alternative distribution r(\\boldsymbol{x}) and that our importance sampling distribution r(\\boldsymbol{x}) can be used to mitigate the problem of high variance and an exceedingly small expectation \\mathbb{E}_{r^{(t)}(\\boldsymbol{x})} \\big[P(S^{(t)}|\\boldsymbol{x}\\big] . This approach is not without drawbacks however, and perturbations in weight space can have deleterious effects on the estimator. Thus, the objective can be rewritten as: \\begin{align} & = \\mathbb{E}_{r(\\boldsymbol{x})}\\Bigg[\\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{r(x)}[P(S|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)]\\Bigg] \\newline & = \\mathbb{E}_{q(\\boldsymbol{x}|\\phi^{(t)})}\\Bigg[\\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{q(\\boldsymbol{x}|\\phi^{(t)})}[P(S^{(t)}|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)]\\Bigg] \\end{align} where p(\\boldsymbol{x}|\\theta^{(0)}) is our target density, q(\\boldsymbol{x}|\\phi^{(t)}) is our proposed density and the ratio of the two: \\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{q(\\boldsymbol{x}|\\phi^{(t)})} \\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{q(\\boldsymbol{x}|\\phi^{(t)})} is the eponymous importance weight . Now that we have this objective and given samples \\{x^{(i)} \\}^{(n)}_{i} from q(\\boldsymbol{x}|\\phi^{(t)}) , we can construct MC estimates: \\begin{align} & \\phi^{(t+1)} = \\underset{\\phi}{\\operatorname{argmin}}\\sum_{i=1}^{M} \\frac{p(\\boldsymbol{x}_{i}^{(t)}|\\theta^{(0)})}{q(\\boldsymbol{x}_{i}^{(t)}|\\phi^{(t)})} P(S^{(t)}|\\boldsymbol{x}_{i}^{(t)}) \\log q(\\boldsymbol{x}_{i}^{(t)}|\\phi)] \\end{align} I think this is a particularly clever reformulation because it does not constrain the authors' choice of search model distribution to a single model class. For example, for cases where marginalization over latent space is intractable and the CbAS objective cannot be solved exactly (i.e. where a vanilla VAE is used), approximate inference approaches can be used instead to extend the model class, something I alluded to earlier. I'm not going to go through the explicit derivation of the ELBO-like objective but it's worth noting that in many cases where the CbAS update can be solved, this product: \\begin{align} \\require{color} & \\phi^{(t+1)} = \\underset{\\phi}{\\operatorname{argmin}}\\sum_{i=1}^{M} \\colorbox{GreenYellow}{$\\frac{p(\\boldsymbol{x}_{i}^{(t)}|\\theta^{(0)})}{q(\\boldsymbol{x}_{i}^{(t)}|\\phi^{(t)})} P(S^{(t)}|\\boldsymbol{x}_{i}^{(t)})$} \\log q(\\boldsymbol{x}_{i}^{(t)}|\\phi)] \\end{align} translates to an importance weighting of the probability of a series of property value sets S^{(t)} conditioned on each data point, \\boldsymbol{x}_{i}^{(t)} (i.e. the weight of each data point). This is similar to a weighted maximum likelihood objective and can therefore be optimized using any number of standard approaches for training generative models. More to come on the experimental results in the next entry... A good entry point to Listgarten's earlier work is her interview on Talking Machines , where she discusses her work at MSR New England on predicting off-target effects for CRISPR guide design. \u21a9 Additional assumptions are that the oracle is well-behaved and noise-free \u21a9 For this, I recommend this chapter from Art Owen's book, \"Monte Carlo theory, methods and examples\". \u21a9","title":"Latest"},{"location":"#on-conditioning-by-adaptive-sampling-part-i","text":"As my very first blog post, I thought I would look at a great, recent paper by David Brookes, Hahnbeom Park, and Jennifer Listgarten 1 , which extends their work from last year that posits a framework, Conditioning by Adaptive Sampling (CbAS) , for model-based conditional density estimation. Of particular relevance to drug design is the application to protein properties. For example, how do we go about optimizing the design of DNA sequences for protein expression, binding, or for protein sequences that maximize properties like secondary structure or fluorescence? Traditionally, in vitro methods for protein engineering have been exhaustive usually involving \"greedy walks\" through protein design space like directed evolution (DE) . This paper proposes a more efficient in silico approach. For this particular entry, I'll summarize the key contributions and introduce some of the core concepts. The subsequent post will walk through the Cross-Entropy Method (CEM) and their experimental results.","title":"On conditioning by adaptive sampling (Part I)"},{"location":"#summary","text":"The main contributions of this paper are as follows: The authors present a method for tackling design problems in discrete space including the problem of maximizing protein fluorescence using avGFP sequence data from Sarkisyan et al. 2016 . A principled approach for conditional density estimation in the presence of rare events and which doesn't constrain the oracle by requiring differentiability. This has the added benefit of recapitulating models in various scientific domains which may not be readily differentiable to begin with It also allows for a degree of flexibility of validation by using wet-lab experiments as the oracle. An exact and iterative importance sampling-based estimation method for variance reduction and computationally intractable model densities. Generalizability of CbAS to specification of property values rather than solely maximization (e.g. a protein fluorescing at a desired wavelength as opposed to being maximally fluorescent).","title":"Summary"},{"location":"#oracles-and-oracle-properties","text":"In order to understand the problem setting in the paper, it's worth briefly reviewing oracles. In statistics, oracle and oracle properties have been extensively used in the context of high-dimensional model estimation and feature selection whereby we have a response vector \\boldsymbol{y} = (y_1,...,y_n)^{T} and input vector of linearly independent features \\boldsymbol{x_j} = (x_{1j},...,x_{nj})^{T} with j = 1,..,p . Under the assumption that we have \\mathbb{A} = \\{ j: \\hat{\\beta} \\neq 0 \\} , the true model only depends on a subset X_{S} \\subset X of its feature space. Briefly put, an oracle property is a theoretical attribute ascribed to a model if it performs as well as if the correct underlying model were given in advance. More formally and following Fan and Li 2001 , Fan and Peng 2004 , and Zou 2006 , we call a given fitting procedure \\delta an oracle if \\hat{\\beta}(\\delta) , the coefficient estimator, identifies the right subset model, \\{ j: \\hat{\\beta} \\neq 0 \\} = \\mathbb{A} with some optimal estimation rate: \\sqrt{n} \\hat{\\beta}(\\delta)_{\\mathbb{A}} - \\beta^*_{\\mathbb{A}}) \\to \\mathcal{N} (0, I^{-1}(\\beta^*_\\mathbb{A})) Thus, the oracle property holds that the asymptotic distribution of the estimator is the same as the asymptotic distribution of the MLE only on the true support. That is, the estimator adapts to knowing the true support without incurring a price. Why is this important? For the authors, they argue that their oracle p(y|\\boldsymbol{x}) effectively serves as a proxy for expensive and exhaustive laboratory-based property measurements. They also make the assumption that given an input, such as a DNA sequence, the oracle 2 returns a distribution over the properties of interest. It's worth noting that this is within the context of the generative setting where we model the joint probability distribution p(\\boldsymbol{x}, y) . Given the property oracle then, one can subsequently model and empirically sample from the underlying data distribution p_{d}(\\boldsymbol{x}) with a generative model p(\\boldsymbol{x}|\\theta) whose prior is conditioned on the desiderata encoded in property values S . The claim here is that this gives a certain degree of flexibility in specifying priors on the design space, unlike G\u00f3mez-Bombarelli et al. 2018 and Killoran et al. 2017 , which utilize a fixed VAE and GAN respectively. Lastly, it's worth noting that they do not require their oracle to be differentiable and this additionally circumvents backpropagation through discrete input space.","title":"Oracles and oracle properties"},{"location":"#conditioning-by-adaptive-sampling","text":"The problem setting is as follows: find settings of the discrete random vector \\boldsymbol{x} \\in \\mathbb{N}^{L} (e.g. representative of DNA sequences) that have a high probability of satisfying some property desiderata (e.g. maximal fluoresence of a protein). The inference problem is expressed as: p(\\boldsymbol{x}|S, \\theta^{(0)}) = \\frac{P(S|\\boldsymbol{x})p(\\boldsymbol{x}|\\theta^{(0)})}{P(S|\\theta^{(0)})} p(\\boldsymbol{x}|S, \\theta^{(0)}) = \\frac{P(S|\\boldsymbol{x})p(\\boldsymbol{x}|\\theta^{(0)})}{P(S|\\theta^{(0)})} where P(S|\\theta^{(0)}) = \\int_{s} P(S|\\boldsymbol{x})p(\\boldsymbol{x}|\\theta^{(0)}) d\\boldsymbol{x} . Like variational inference , the marginal probability of CbAS yields no analytic solution as the sum over all possible configurations of the latent structures and its parameters is intractable. Unsurprisingly, inference for CbAS is VI-like in that they minimize the KL divergence between the conditional and the approximating search model, q(\\boldsymbol{x}|\\phi) : \\phi^{*} = \\underset{\\phi}{\\operatorname{argmin}} D_{KL} \\big(p(\\boldsymbol{x}|S,\\theta^{(0)})||q(\\boldsymbol{x}|\\phi\\big) \\phi^{*} = \\underset{\\phi}{\\operatorname{argmin}} D_{KL} \\big(p(\\boldsymbol{x}|S,\\theta^{(0)})||q(\\boldsymbol{x}|\\phi\\big) This can be re-written in terms of the log expectation of the difference between the search model distribution and the target conditional distribution, similar to how the Evidence Lower Bound (ELBO) can be derived: \\underset{\\phi}{\\operatorname{argmin}}\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log p(\\boldsymbol{x}|S,\\theta^{(0)}) - \\log q(\\boldsymbol{x}|\\phi)] \\underset{\\phi}{\\operatorname{argmin}}\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log p(\\boldsymbol{x}|S,\\theta^{(0)}) - \\log q(\\boldsymbol{x}|\\phi)] Thus, the second expectation can be expressed as the entropy of the target conditional distribution H_{0} \\equiv -\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log p(\\boldsymbol{x}|S,\\theta^{(0)})] : \\begin{align} & = \\underset{\\phi}{\\operatorname{argmin}}-\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log q(\\boldsymbol{x}|\\phi)] - H_{0} \\newline & = \\underset{\\phi}{\\operatorname{argmax}} \\frac{1}{P(S|\\theta^{(0)})} \\mathbb{E}_{(p(\\boldsymbol{x}|S,\\theta^{(0)})}[P(S|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)] \\newline & = \\underset{\\phi}{\\operatorname{argmax}}\\mathbb{E}_{p(\\boldsymbol{x}|\\theta^{(0)})}[P(S|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)] & \\scriptstyle{H_{0}, P(S|\\theta^{(0)}) \\text{ dropped}} \\\\[2mm] \\end{align} The authors also note that the difficulty of estimating the normalizing constant is compounded by the fact that S (and by definition, P(S|\\boldsymbol{x}) ) is \"exceedingly rare\". This translates to difficulties in optimization: any gradient-based reparameterization which yields differentiable Monte Carlo (MC) estimates of our expectation (i.e. the 'reparameterization trick' from Kingma and Welling 2014 ) would require a non-trivial number of samples to be accurate and be very challenging for distributions over discrete state spaces. To put it another way, any naive MC estimation would require an intensive simulation effort, inversely proportional to the magnitude of P(S|\\boldsymbol{x}) .","title":"Conditioning by adaptive sampling"},{"location":"#importance-sampling-based-estimation","text":"I'm not going to review importance sampling here 3 . Suffice to say that the basic idea is that we can estimate the expectation of a random variable under one distribution p(\\boldsymbol{x}) from samples of an alternative distribution r(\\boldsymbol{x}) and that our importance sampling distribution r(\\boldsymbol{x}) can be used to mitigate the problem of high variance and an exceedingly small expectation \\mathbb{E}_{r^{(t)}(\\boldsymbol{x})} \\big[P(S^{(t)}|\\boldsymbol{x}\\big] . This approach is not without drawbacks however, and perturbations in weight space can have deleterious effects on the estimator. Thus, the objective can be rewritten as: \\begin{align} & = \\mathbb{E}_{r(\\boldsymbol{x})}\\Bigg[\\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{r(x)}[P(S|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)]\\Bigg] \\newline & = \\mathbb{E}_{q(\\boldsymbol{x}|\\phi^{(t)})}\\Bigg[\\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{q(\\boldsymbol{x}|\\phi^{(t)})}[P(S^{(t)}|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)]\\Bigg] \\end{align} where p(\\boldsymbol{x}|\\theta^{(0)}) is our target density, q(\\boldsymbol{x}|\\phi^{(t)}) is our proposed density and the ratio of the two: \\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{q(\\boldsymbol{x}|\\phi^{(t)})} \\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{q(\\boldsymbol{x}|\\phi^{(t)})} is the eponymous importance weight . Now that we have this objective and given samples \\{x^{(i)} \\}^{(n)}_{i} from q(\\boldsymbol{x}|\\phi^{(t)}) , we can construct MC estimates: \\begin{align} & \\phi^{(t+1)} = \\underset{\\phi}{\\operatorname{argmin}}\\sum_{i=1}^{M} \\frac{p(\\boldsymbol{x}_{i}^{(t)}|\\theta^{(0)})}{q(\\boldsymbol{x}_{i}^{(t)}|\\phi^{(t)})} P(S^{(t)}|\\boldsymbol{x}_{i}^{(t)}) \\log q(\\boldsymbol{x}_{i}^{(t)}|\\phi)] \\end{align} I think this is a particularly clever reformulation because it does not constrain the authors' choice of search model distribution to a single model class. For example, for cases where marginalization over latent space is intractable and the CbAS objective cannot be solved exactly (i.e. where a vanilla VAE is used), approximate inference approaches can be used instead to extend the model class, something I alluded to earlier. I'm not going to go through the explicit derivation of the ELBO-like objective but it's worth noting that in many cases where the CbAS update can be solved, this product: \\begin{align} \\require{color} & \\phi^{(t+1)} = \\underset{\\phi}{\\operatorname{argmin}}\\sum_{i=1}^{M} \\colorbox{GreenYellow}{$\\frac{p(\\boldsymbol{x}_{i}^{(t)}|\\theta^{(0)})}{q(\\boldsymbol{x}_{i}^{(t)}|\\phi^{(t)})} P(S^{(t)}|\\boldsymbol{x}_{i}^{(t)})$} \\log q(\\boldsymbol{x}_{i}^{(t)}|\\phi)] \\end{align} translates to an importance weighting of the probability of a series of property value sets S^{(t)} conditioned on each data point, \\boldsymbol{x}_{i}^{(t)} (i.e. the weight of each data point). This is similar to a weighted maximum likelihood objective and can therefore be optimized using any number of standard approaches for training generative models. More to come on the experimental results in the next entry... A good entry point to Listgarten's earlier work is her interview on Talking Machines , where she discusses her work at MSR New England on predicting off-target effects for CRISPR guide design. \u21a9 Additional assumptions are that the oracle is well-behaved and noise-free \u21a9 For this, I recommend this chapter from Art Owen's book, \"Monte Carlo theory, methods and examples\". \u21a9","title":"Importance sampling-based estimation"},{"location":"05-07-19-adaptive-sampling/","text":"On conditioning by adaptive sampling (Part I) As my very first blog post, I thought I would look at a great, recent paper by David Brookes, Hahnbeom Park, and Jennifer Listgarten 1 , which extends their work from last year that posits a framework, Conditioning by Adaptive Sampling (CbAS) , for model-based conditional density estimation. Of particular relevance to drug design is the application to protein properties. For example, how do we go about optimizing the design of DNA sequences for protein expression, binding, or for protein sequences that maximize properties like secondary structure or fluorescence? Traditionally, in vitro methods for protein engineering have been exhaustive usually involving \"greedy walks\" through protein design space like directed evolution (DE) . This paper proposes a more efficient in silico approach. For this particular entry, I'll summarize the key contributions and introduce some of the core concepts. The subsequent post will walk through the Cross-Entropy Method (CEM) and their experimental results. Summary The main contributions of this paper are as follows: The authors present a method for tackling design problems in discrete space including the problem of maximizing protein fluorescence using avGFP sequence data from Sarkisyan et al. 2016 . A principled approach for conditional density estimation in the presence of rare events and which doesn't constrain the oracle by requiring differentiability. This has the added benefit of recapitulating models in various scientific domains which may not be readily differentiable to begin with It also allows for a degree of flexibility of validation by using wet-lab experiments as the oracle. An exact and iterative importance sampling-based estimation method for variance reduction and computationally intractable model densities. Generalizability of CbAS to specification of property values rather than solely maximization (e.g. a protein fluorescing at a desired wavelength as opposed to being maximally fluorescent). Oracles and oracle properties In order to understand the problem setting in the paper, it's worth briefly reviewing oracles. In statistics, oracle and oracle properties have been extensively used in the context of high-dimensional model estimation and feature selection whereby we have a response vector \\boldsymbol{y} = (y_1,...,y_n)^{T} and input vector of linearly independent features \\boldsymbol{x_j} = (x_{1j},...,x_{nj})^{T} with j = 1,..,p . Under the assumption that we have \\mathbb{A} = \\{ j: \\hat{\\beta} \\neq 0 \\} , the true model only depends on a subset X_{S} \\subset X of its feature space. Briefly put, an oracle property is a theoretical attribute ascribed to a model if it performs as well as if the correct underlying model were given in advance. More formally and following Fan and Li 2001 , Fan and Peng 2004 , and Zou 2006 , we call a given fitting procedure \\delta an oracle if \\hat{\\beta}(\\delta) , the coefficient estimator, identifies the right subset model, \\{ j: \\hat{\\beta} \\neq 0 \\} = \\mathbb{A} with some optimal estimation rate: \\sqrt{n} \\hat{\\beta}(\\delta)_{\\mathbb{A}} - \\beta^*_{\\mathbb{A}}) \\to \\mathcal{N} (0, I^{-1}(\\beta^*_\\mathbb{A})) Thus, the oracle property holds that the asymptotic distribution of the estimator is the same as the asymptotic distribution of the MLE only on the true support. That is, the estimator adapts to knowing the true support without incurring a price. Why is this important? For the authors, they argue that their oracle p(y|\\boldsymbol{x}) effectively serves as a proxy for expensive and exhaustive laboratory-based property measurements. They also make the assumption that given an input, such as a DNA sequence, the oracle 2 returns a distribution over the properties of interest. It's worth noting that this is within the context of the generative setting where we model the joint probability distribution p(\\boldsymbol{x}, y) . Given the property oracle then, one can subsequently model and empirically sample from the underlying data distribution p_{d}(\\boldsymbol{x}) with a generative model p(\\boldsymbol{x}|\\theta) whose prior is conditioned on the desiderata encoded in property values S . The claim here is that this gives a certain degree of flexibility in specifying priors on the design space, unlike G\u00f3mez-Bombarelli et al. 2018 and Killoran et al. 2017 , which utilize a fixed VAE and GAN respectively. Lastly, it's worth noting that they do not require their oracle to be differentiable and this additionally circumvents backpropagation through discrete input space. Conditioning by adaptive sampling The problem setting is as follows: find settings of the discrete random vector \\boldsymbol{x} \\in \\mathbb{N}^{L} (e.g. representative of DNA sequences) that have a high probability of satisfying some property desiderata (e.g. maximal fluoresence of a protein). The inference problem is expressed as: p(\\boldsymbol{x}|S, \\theta^{(0)}) = \\frac{P(S|\\boldsymbol{x})p(\\boldsymbol{x}|\\theta^{(0)})}{P(S|\\theta^{(0)})} p(\\boldsymbol{x}|S, \\theta^{(0)}) = \\frac{P(S|\\boldsymbol{x})p(\\boldsymbol{x}|\\theta^{(0)})}{P(S|\\theta^{(0)})} where P(S|\\theta^{(0)}) = \\int_{s} P(S|\\boldsymbol{x})p(\\boldsymbol{x}|\\theta^{(0)}) d\\boldsymbol{x} . Like variational inference , the marginal probability of CbAS yields no analytic solution as the sum over all possible configurations of the latent structures and its parameters is intractable. Unsurprisingly, inference for CbAS is VI-like in that they minimize the KL divergence between the conditional and the approximating search model, q(\\boldsymbol{x}|\\phi) : \\phi^{*} = \\underset{\\phi}{\\operatorname{argmin}} D_{KL} \\big(p(\\boldsymbol{x}|S,\\theta^{(0)})||q(\\boldsymbol{x}|\\phi\\big) \\phi^{*} = \\underset{\\phi}{\\operatorname{argmin}} D_{KL} \\big(p(\\boldsymbol{x}|S,\\theta^{(0)})||q(\\boldsymbol{x}|\\phi\\big) This can be re-written in terms of the log expectation of the difference between the search model distribution and the target conditional distribution, similar to how the Evidence Lower Bound (ELBO) can be derived: \\underset{\\phi}{\\operatorname{argmin}}\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log p(\\boldsymbol{x}|S,\\theta^{(0)}) - \\log q(\\boldsymbol{x}|\\phi)] \\underset{\\phi}{\\operatorname{argmin}}\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log p(\\boldsymbol{x}|S,\\theta^{(0)}) - \\log q(\\boldsymbol{x}|\\phi)] Thus, the second expectation can be expressed as the entropy of the target conditional distribution H_{0} \\equiv -\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log p(\\boldsymbol{x}|S,\\theta^{(0)})] : \\begin{align} & = \\underset{\\phi}{\\operatorname{argmin}}-\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log q(\\boldsymbol{x}|\\phi)] - H_{0} \\newline & = \\underset{\\phi}{\\operatorname{argmax}} \\frac{1}{P(S|\\theta^{(0)})} \\mathbb{E}_{(p(\\boldsymbol{x}|S,\\theta^{(0)})}[P(S|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)] \\newline & = \\underset{\\phi}{\\operatorname{argmax}}\\mathbb{E}_{p(\\boldsymbol{x}|\\theta^{(0)})}[P(S|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)] & \\scriptstyle{H_{0}, P(S|\\theta^{(0)}) \\text{ dropped}} \\\\[2mm] \\end{align} The authors also note that the difficulty of estimating the normalizing constant is compounded by the fact that S (and by definition, P(S|\\boldsymbol{x}) ) is \"exceedingly rare\". This translates to difficulties in optimization: any gradient-based reparameterization which yields differentiable Monte Carlo (MC) estimates of our expectation (i.e. the 'reparameterization trick' from Kingma and Welling 2014 ) would require a non-trivial number of samples to be accurate and be very challenging for distributions over discrete state spaces. To put it another way, any naive MC estimation would require an intensive simulation effort, inversely proportional to the magnitude of P(S|\\boldsymbol{x}) . Importance sampling-based estimation I'm not going to review importance sampling here 3 . Suffice to say that the basic idea is that we can estimate the expectation of a random variable under one distribution p(\\boldsymbol{x}) from samples of an alternative distribution r(\\boldsymbol{x}) and that our importance sampling distribution r(\\boldsymbol{x}) can be used to mitigate the problem of high variance and an exceedingly small expectation \\mathbb{E}_{r^{(t)}(\\boldsymbol{x})} \\big[P(S^{(t)}|\\boldsymbol{x}\\big] . This approach is not without drawbacks however, and perturbations in weight space can have deleterious effects on the estimator. Thus, the objective can be rewritten as: \\begin{align} & = \\mathbb{E}_{r(\\boldsymbol{x})}\\Bigg[\\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{r(x)}[P(S|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)]\\Bigg] \\newline & = \\mathbb{E}_{q(\\boldsymbol{x}|\\phi^{(t)})}\\Bigg[\\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{q(\\boldsymbol{x}|\\phi^{(t)})}[P(S^{(t)}|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)]\\Bigg] \\end{align} where p(\\boldsymbol{x}|\\theta^{(0)}) is our target density, q(\\boldsymbol{x}|\\phi^{(t)}) is our proposed density and the ratio of the two: \\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{q(\\boldsymbol{x}|\\phi^{(t)})} \\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{q(\\boldsymbol{x}|\\phi^{(t)})} is the eponymous importance weight . Now that we have this objective and given samples \\{x^{(i)} \\}^{(n)}_{i} from q(\\boldsymbol{x}|\\phi^{(t)}) , we can construct MC estimates: \\begin{align} & \\phi^{(t+1)} = \\underset{\\phi}{\\operatorname{argmin}}\\sum_{i=1}^{M} \\frac{p(\\boldsymbol{x}_{i}^{(t)}|\\theta^{(0)})}{q(\\boldsymbol{x}_{i}^{(t)}|\\phi^{(t)})} P(S^{(t)}|\\boldsymbol{x}_{i}^{(t)}) \\log q(\\boldsymbol{x}_{i}^{(t)}|\\phi)] \\end{align} I think this is a particularly clever reformulation because it does not constrain the authors' choice of search model distribution to a single model class. For example, for cases where marginalization over latent space is intractable and the CbAS objective cannot be solved exactly (i.e. where a vanilla VAE is used), approximate inference approaches can be used instead to extend the model class, something I alluded to earlier. I'm not going to go through the explicit derivation of the ELBO-like objective but it's worth noting that in many cases where the CbAS update can be solved, this product: \\begin{align} \\require{color} & \\phi^{(t+1)} = \\underset{\\phi}{\\operatorname{argmin}}\\sum_{i=1}^{M} \\colorbox{GreenYellow}{$\\frac{p(\\boldsymbol{x}_{i}^{(t)}|\\theta^{(0)})}{q(\\boldsymbol{x}_{i}^{(t)}|\\phi^{(t)})} P(S^{(t)}|\\boldsymbol{x}_{i}^{(t)})$} \\log q(\\boldsymbol{x}_{i}^{(t)}|\\phi)] \\end{align} translates to an importance weighting of the probability of a series of property value sets S^{(t)} conditioned on each data point, \\boldsymbol{x}_{i}^{(t)} (i.e. the weight of each data point). This is similar to a weighted maximum likelihood objective and can therefore be optimized using any number of standard approaches for training generative models. More to come on the experimental results in the next entry... A good entry point to Listgarten's earlier work is her interview on Talking Machines , where she discusses her work at MSR New England on predicting off-target effects for CRISPR guide design. \u21a9 Additional assumptions are that the oracle is well-behaved and noise-free \u21a9 For this, I recommend this chapter from Art Owen's book, \"Monte Carlo theory, methods and examples\". \u21a9","title":"On conditioning by adaptive sampling"},{"location":"05-07-19-adaptive-sampling/#on-conditioning-by-adaptive-sampling-part-i","text":"As my very first blog post, I thought I would look at a great, recent paper by David Brookes, Hahnbeom Park, and Jennifer Listgarten 1 , which extends their work from last year that posits a framework, Conditioning by Adaptive Sampling (CbAS) , for model-based conditional density estimation. Of particular relevance to drug design is the application to protein properties. For example, how do we go about optimizing the design of DNA sequences for protein expression, binding, or for protein sequences that maximize properties like secondary structure or fluorescence? Traditionally, in vitro methods for protein engineering have been exhaustive usually involving \"greedy walks\" through protein design space like directed evolution (DE) . This paper proposes a more efficient in silico approach. For this particular entry, I'll summarize the key contributions and introduce some of the core concepts. The subsequent post will walk through the Cross-Entropy Method (CEM) and their experimental results.","title":"On conditioning by adaptive sampling (Part I)"},{"location":"05-07-19-adaptive-sampling/#summary","text":"The main contributions of this paper are as follows: The authors present a method for tackling design problems in discrete space including the problem of maximizing protein fluorescence using avGFP sequence data from Sarkisyan et al. 2016 . A principled approach for conditional density estimation in the presence of rare events and which doesn't constrain the oracle by requiring differentiability. This has the added benefit of recapitulating models in various scientific domains which may not be readily differentiable to begin with It also allows for a degree of flexibility of validation by using wet-lab experiments as the oracle. An exact and iterative importance sampling-based estimation method for variance reduction and computationally intractable model densities. Generalizability of CbAS to specification of property values rather than solely maximization (e.g. a protein fluorescing at a desired wavelength as opposed to being maximally fluorescent).","title":"Summary"},{"location":"05-07-19-adaptive-sampling/#oracles-and-oracle-properties","text":"In order to understand the problem setting in the paper, it's worth briefly reviewing oracles. In statistics, oracle and oracle properties have been extensively used in the context of high-dimensional model estimation and feature selection whereby we have a response vector \\boldsymbol{y} = (y_1,...,y_n)^{T} and input vector of linearly independent features \\boldsymbol{x_j} = (x_{1j},...,x_{nj})^{T} with j = 1,..,p . Under the assumption that we have \\mathbb{A} = \\{ j: \\hat{\\beta} \\neq 0 \\} , the true model only depends on a subset X_{S} \\subset X of its feature space. Briefly put, an oracle property is a theoretical attribute ascribed to a model if it performs as well as if the correct underlying model were given in advance. More formally and following Fan and Li 2001 , Fan and Peng 2004 , and Zou 2006 , we call a given fitting procedure \\delta an oracle if \\hat{\\beta}(\\delta) , the coefficient estimator, identifies the right subset model, \\{ j: \\hat{\\beta} \\neq 0 \\} = \\mathbb{A} with some optimal estimation rate: \\sqrt{n} \\hat{\\beta}(\\delta)_{\\mathbb{A}} - \\beta^*_{\\mathbb{A}}) \\to \\mathcal{N} (0, I^{-1}(\\beta^*_\\mathbb{A})) Thus, the oracle property holds that the asymptotic distribution of the estimator is the same as the asymptotic distribution of the MLE only on the true support. That is, the estimator adapts to knowing the true support without incurring a price. Why is this important? For the authors, they argue that their oracle p(y|\\boldsymbol{x}) effectively serves as a proxy for expensive and exhaustive laboratory-based property measurements. They also make the assumption that given an input, such as a DNA sequence, the oracle 2 returns a distribution over the properties of interest. It's worth noting that this is within the context of the generative setting where we model the joint probability distribution p(\\boldsymbol{x}, y) . Given the property oracle then, one can subsequently model and empirically sample from the underlying data distribution p_{d}(\\boldsymbol{x}) with a generative model p(\\boldsymbol{x}|\\theta) whose prior is conditioned on the desiderata encoded in property values S . The claim here is that this gives a certain degree of flexibility in specifying priors on the design space, unlike G\u00f3mez-Bombarelli et al. 2018 and Killoran et al. 2017 , which utilize a fixed VAE and GAN respectively. Lastly, it's worth noting that they do not require their oracle to be differentiable and this additionally circumvents backpropagation through discrete input space.","title":"Oracles and oracle properties"},{"location":"05-07-19-adaptive-sampling/#conditioning-by-adaptive-sampling","text":"The problem setting is as follows: find settings of the discrete random vector \\boldsymbol{x} \\in \\mathbb{N}^{L} (e.g. representative of DNA sequences) that have a high probability of satisfying some property desiderata (e.g. maximal fluoresence of a protein). The inference problem is expressed as: p(\\boldsymbol{x}|S, \\theta^{(0)}) = \\frac{P(S|\\boldsymbol{x})p(\\boldsymbol{x}|\\theta^{(0)})}{P(S|\\theta^{(0)})} p(\\boldsymbol{x}|S, \\theta^{(0)}) = \\frac{P(S|\\boldsymbol{x})p(\\boldsymbol{x}|\\theta^{(0)})}{P(S|\\theta^{(0)})} where P(S|\\theta^{(0)}) = \\int_{s} P(S|\\boldsymbol{x})p(\\boldsymbol{x}|\\theta^{(0)}) d\\boldsymbol{x} . Like variational inference , the marginal probability of CbAS yields no analytic solution as the sum over all possible configurations of the latent structures and its parameters is intractable. Unsurprisingly, inference for CbAS is VI-like in that they minimize the KL divergence between the conditional and the approximating search model, q(\\boldsymbol{x}|\\phi) : \\phi^{*} = \\underset{\\phi}{\\operatorname{argmin}} D_{KL} \\big(p(\\boldsymbol{x}|S,\\theta^{(0)})||q(\\boldsymbol{x}|\\phi\\big) \\phi^{*} = \\underset{\\phi}{\\operatorname{argmin}} D_{KL} \\big(p(\\boldsymbol{x}|S,\\theta^{(0)})||q(\\boldsymbol{x}|\\phi\\big) This can be re-written in terms of the log expectation of the difference between the search model distribution and the target conditional distribution, similar to how the Evidence Lower Bound (ELBO) can be derived: \\underset{\\phi}{\\operatorname{argmin}}\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log p(\\boldsymbol{x}|S,\\theta^{(0)}) - \\log q(\\boldsymbol{x}|\\phi)] \\underset{\\phi}{\\operatorname{argmin}}\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log p(\\boldsymbol{x}|S,\\theta^{(0)}) - \\log q(\\boldsymbol{x}|\\phi)] Thus, the second expectation can be expressed as the entropy of the target conditional distribution H_{0} \\equiv -\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log p(\\boldsymbol{x}|S,\\theta^{(0)})] : \\begin{align} & = \\underset{\\phi}{\\operatorname{argmin}}-\\mathbb{E}_{p(\\boldsymbol{x}|S,\\theta^{(0)})}[\\log q(\\boldsymbol{x}|\\phi)] - H_{0} \\newline & = \\underset{\\phi}{\\operatorname{argmax}} \\frac{1}{P(S|\\theta^{(0)})} \\mathbb{E}_{(p(\\boldsymbol{x}|S,\\theta^{(0)})}[P(S|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)] \\newline & = \\underset{\\phi}{\\operatorname{argmax}}\\mathbb{E}_{p(\\boldsymbol{x}|\\theta^{(0)})}[P(S|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)] & \\scriptstyle{H_{0}, P(S|\\theta^{(0)}) \\text{ dropped}} \\\\[2mm] \\end{align} The authors also note that the difficulty of estimating the normalizing constant is compounded by the fact that S (and by definition, P(S|\\boldsymbol{x}) ) is \"exceedingly rare\". This translates to difficulties in optimization: any gradient-based reparameterization which yields differentiable Monte Carlo (MC) estimates of our expectation (i.e. the 'reparameterization trick' from Kingma and Welling 2014 ) would require a non-trivial number of samples to be accurate and be very challenging for distributions over discrete state spaces. To put it another way, any naive MC estimation would require an intensive simulation effort, inversely proportional to the magnitude of P(S|\\boldsymbol{x}) .","title":"Conditioning by adaptive sampling"},{"location":"05-07-19-adaptive-sampling/#importance-sampling-based-estimation","text":"I'm not going to review importance sampling here 3 . Suffice to say that the basic idea is that we can estimate the expectation of a random variable under one distribution p(\\boldsymbol{x}) from samples of an alternative distribution r(\\boldsymbol{x}) and that our importance sampling distribution r(\\boldsymbol{x}) can be used to mitigate the problem of high variance and an exceedingly small expectation \\mathbb{E}_{r^{(t)}(\\boldsymbol{x})} \\big[P(S^{(t)}|\\boldsymbol{x}\\big] . This approach is not without drawbacks however, and perturbations in weight space can have deleterious effects on the estimator. Thus, the objective can be rewritten as: \\begin{align} & = \\mathbb{E}_{r(\\boldsymbol{x})}\\Bigg[\\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{r(x)}[P(S|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)]\\Bigg] \\newline & = \\mathbb{E}_{q(\\boldsymbol{x}|\\phi^{(t)})}\\Bigg[\\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{q(\\boldsymbol{x}|\\phi^{(t)})}[P(S^{(t)}|\\boldsymbol{x}) \\log q(\\boldsymbol{x}|\\phi)]\\Bigg] \\end{align} where p(\\boldsymbol{x}|\\theta^{(0)}) is our target density, q(\\boldsymbol{x}|\\phi^{(t)}) is our proposed density and the ratio of the two: \\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{q(\\boldsymbol{x}|\\phi^{(t)})} \\frac{p(\\boldsymbol{x}|\\theta^{(0)})}{q(\\boldsymbol{x}|\\phi^{(t)})} is the eponymous importance weight . Now that we have this objective and given samples \\{x^{(i)} \\}^{(n)}_{i} from q(\\boldsymbol{x}|\\phi^{(t)}) , we can construct MC estimates: \\begin{align} & \\phi^{(t+1)} = \\underset{\\phi}{\\operatorname{argmin}}\\sum_{i=1}^{M} \\frac{p(\\boldsymbol{x}_{i}^{(t)}|\\theta^{(0)})}{q(\\boldsymbol{x}_{i}^{(t)}|\\phi^{(t)})} P(S^{(t)}|\\boldsymbol{x}_{i}^{(t)}) \\log q(\\boldsymbol{x}_{i}^{(t)}|\\phi)] \\end{align} I think this is a particularly clever reformulation because it does not constrain the authors' choice of search model distribution to a single model class. For example, for cases where marginalization over latent space is intractable and the CbAS objective cannot be solved exactly (i.e. where a vanilla VAE is used), approximate inference approaches can be used instead to extend the model class, something I alluded to earlier. I'm not going to go through the explicit derivation of the ELBO-like objective but it's worth noting that in many cases where the CbAS update can be solved, this product: \\begin{align} \\require{color} & \\phi^{(t+1)} = \\underset{\\phi}{\\operatorname{argmin}}\\sum_{i=1}^{M} \\colorbox{GreenYellow}{$\\frac{p(\\boldsymbol{x}_{i}^{(t)}|\\theta^{(0)})}{q(\\boldsymbol{x}_{i}^{(t)}|\\phi^{(t)})} P(S^{(t)}|\\boldsymbol{x}_{i}^{(t)})$} \\log q(\\boldsymbol{x}_{i}^{(t)}|\\phi)] \\end{align} translates to an importance weighting of the probability of a series of property value sets S^{(t)} conditioned on each data point, \\boldsymbol{x}_{i}^{(t)} (i.e. the weight of each data point). This is similar to a weighted maximum likelihood objective and can therefore be optimized using any number of standard approaches for training generative models. More to come on the experimental results in the next entry... A good entry point to Listgarten's earlier work is her interview on Talking Machines , where she discusses her work at MSR New England on predicting off-target effects for CRISPR guide design. \u21a9 Additional assumptions are that the oracle is well-behaved and noise-free \u21a9 For this, I recommend this chapter from Art Owen's book, \"Monte Carlo theory, methods and examples\". \u21a9","title":"Importance sampling-based estimation"},{"location":"about/","text":"Hi there. I am a machine learning research scientist at Pfizer R&D and part of the Simulation and Modeling Sciences group. I have research interests at the intersection of machine learning, Bayesian statistics, and the computational sciences and am passionate about developing approaches from first principles to solve different problems in drug discovery.","title":"About"},{"location":"publications/","text":"Peer-Reviewed Publications FAAH genetic variation enhances frontoamygdala function in mouse and human Iva Dincheva, Andrew T. Drysdale, Catherine A. Hartley, David C. Johnson, Deqiang Jing, Elizabeth C. King, Stephen Ra , J. Megan Gray, Ruirong Yang, Ann Marie DeGruccio, Chienchun Huang, Charles E. Glatt, Matthew N. Hill, B.J. Casey, Francis Lee Nature Communications , 2015; 6, 6395. doi:10.1038/ncomms7395 Paper Variation in endocannabinoid signaling modulates frontoamygdala connectivity, fear regulation, and anxiety in mice and humans Andrew T. Drysdale, Iva Dincheva, Catherine A. Hartley, David C. Johnson, Deqiang Jing, Elizabeth C. King, Stephen Ra , J. Megan Gray, Ruirong Yang, Ann Marie DeGruccio, Chienchun Huang, Charles E. Glatt, Matthew N Hill, BJ Casey, Francis S. Lee Biological Psychiatry , 2015; 77(9), 81S. Forebrain elimination of cacna1c mediates anxiety-like behavior in mice Anni S. Lee 1 , Stephen Ra 1 , Aditi M. Rajadhyaksha, Jeremiah K. Britt, H\u00e9ctor De Jes\u00fas-Cort\u00e9s, KL Gonzales, Amy Lee, Sven Moosmang, Franz Hofmann, Andrew A. Pieper, Anjali M. Rajadhyaksha Molecular Psychiatry , 2012; 17, 1054-55. doi:10.1038/mp.2012.71 Paper Behavioral characterization of cereblon forebrain-specific conditional null mice: a model for human non-syndromic intellectual disability Anjali M. Rajadhyaksha, Stephen Ra , Sarah Kishinevsky, Anni S. Lee, Peter Romanienko, Mariel DuBoff, Chingwen Yang, Bojana Zupan, Maureen Byrne, Zeeba R. Daruwalla, Willie Mark, Barry E. Kosofsky, Miklos Toth, Joseph J. Higgins Behavioural Brain Research , 2012; 226(2), 428-34. doi: 10.1016/j.bbr.2011.09.039 Paper Cav 1.2 L-type Ca 2+ channels mediate cocaine-induced GluA1 trafficking in the nucleus accumbens, a long-term adaptation dependent on ventral vegmental area Cav 1.3 channels Kathryn Schierberl, Jin Hao, Thomas F. Tropea, Stephen Ra , Thomas P. Giordano, Qinghao Xu, Sandra M. Garraway, Franz Hofmann, Sven Moosmang, Joerg Striessnig, Charles E. Inturrisi, Anjali M. Rajadhyaksha Journal of Neuroscience , 2011; 31(38), 13562-75, doi: 10.1523/JNEUROSCI.2315-11.2011 Paper Preprints Deep learning of representations for transcriptomics-based phenotype prediction Aaron M. Smith, Jonathan R. Walsh, John Long, Craig B. Davis, Peter Henstock, Martin R. Hodge, Mateusz Maciejewski, Xinmeng Jasminue Mu, Stephen Ra, Shanrong Zhao, Daniel Ziemek, Charles K. Fisher bioRxiv , 2019. doi:10.1101/574723 Paper | Code | Data Conference Papers Deep generative models for the directed expansion of compound libraries Vishnu Sresht, Stephen Ra, Brajesh Rai, Bruce A. Lefker, Alan Mathiowetz American Chemical Society (ACS) National Meeting 2018 , 2012; 17, 1054-55. doi:10.1038/mp.2012.71 Paper","title":"Publications"},{"location":"team/","text":"","title":"Team"}]}